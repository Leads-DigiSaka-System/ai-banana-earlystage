{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOWn1StcIFHx",
        "outputId": "e6c5954a-e66a-439f-978a-8719f28de10c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORTS AND CONFIG** (cell 1)"
      ],
      "metadata": {
        "id": "SmCElp-ONxB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Any, Optional, List\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import yaml\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "# Setup logging (Senior-level: Proper logging instead of print)\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('/content/data_labeling.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ============================================================================\n",
        "# COLAB PATH CONFIGURATION\n",
        "# ============================================================================\n",
        "# Choose ONE of the following options:\n",
        "\n",
        "# OPTION 1: Data in Google Drive (most common)\n",
        "USE_DRIVE = True  # Set to False if data is uploaded to Colab\n",
        "\n",
        "if USE_DRIVE:\n",
        "    # Paths for Google Drive\n",
        "    DRIVE_BASE = Path(\"/content/drive/MyDrive\")\n",
        "    # Update this path to match your Drive folder structure\n",
        "    # Example: DRIVE_BASE / \"ai-banana-earlystage\" / \"Data\" / \"Sigatoka pics\"\n",
        "    DATA_DIR = DRIVE_BASE / \"Machine_Learning\" / \"Sigatoka pics\"\n",
        "    OUTPUT_DIR = DRIVE_BASE / \"Machine_Learning\" / \"Data Labeling\"\n",
        "\n",
        "    print(\"üìÅ Using Google Drive paths\")\n",
        "    print(f\"   Data: {DATA_DIR}\")\n",
        "    print(f\"   Output: {OUTPUT_DIR}\")\n",
        "else:\n",
        "    # OPTION 2: Data uploaded to Colab (use /content/)\n",
        "    DATA_DIR = Path(\"/content/Data/Sigatoka pics\")\n",
        "    OUTPUT_DIR = Path(\"/content/Data Labeling\")\n",
        "\n",
        "    print(\"üìÅ Using Colab workspace paths\")\n",
        "    print(f\"   Data: {DATA_DIR}\")\n",
        "    print(f\"   Output: {OUTPUT_DIR}\")\n",
        "\n",
        "# Validate paths exist\n",
        "if not DATA_DIR.exists():\n",
        "    logger.warning(f\"‚ö†Ô∏è  Data directory not found: {DATA_DIR}\")\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: Data directory not found!\")\n",
        "    print(f\"   Please check the path: {DATA_DIR}\")\n",
        "    print(f\"   Update DATA_DIR in this cell to match your folder structure\")\n",
        "else:\n",
        "    print(f\"‚úÖ Data directory found: {DATA_DIR}\")\n",
        "\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "logger.info(f\"Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"‚úÖ Output directory ready: {OUTPUT_DIR}\")\n",
        "\n",
        "# Class labels mapping\n",
        "CLASS_LABELS = {\n",
        "    \"Healthy\": \"Healthy\",\n",
        "    \"Stage1\": \"Stage1\",\n",
        "    \"Stage2\": \"Stage2\",\n",
        "    \"Stage3\": \"Stage3\",\n",
        "    \"Stage4\": \"Stage4\",\n",
        "    \"Stage5\": \"Stage5\",\n",
        "    \"Stage6\": \"Stage6\"\n",
        "}\n",
        "\n",
        "# Image quality thresholds\n",
        "QUALITY_THRESHOLDS = {\n",
        "    \"min_resolution\": (256, 256),  # Minimum width, height\n",
        "    \"max_blur_threshold\": 100.0,  # Laplacian variance threshold (lower = blurrier)\n",
        "    \"min_brightness\": 20,  # Minimum average brightness (0-255)\n",
        "    \"max_brightness\": 240,  # Maximum average brightness (0-255)\n",
        "    \"min_file_size_kb\": 50,  # Minimum file size in KB\n",
        "    \"max_file_size_mb\": 10,  # Maximum file size in MB\n",
        "}\n",
        "\n",
        "# Supported image formats\n",
        "SUPPORTED_FORMATS = [\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\"]\n",
        "\n",
        "# Metadata fields to extract\n",
        "METADATA_FIELDS = [\n",
        "    \"image_path\",\n",
        "    \"class_label\",\n",
        "    \"width\",\n",
        "    \"height\",\n",
        "    \"file_size_kb\",\n",
        "    \"blur_score\",\n",
        "    \"brightness_score\",\n",
        "    \"quality_status\",\n",
        "    \"timestamp\",\n",
        "    \"source_folder\"\n",
        "]\n",
        "\n",
        "print(\"‚úì Configuration loaded\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJjTQQWcF5k7",
        "outputId": "60916619-9ffa-4630-cf0e-f40c89e3fb17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Using Google Drive paths\n",
            "   Data: /content/drive/MyDrive/Machine_Learning/Sigatoka pics\n",
            "   Output: /content/drive/MyDrive/Machine_Learning/Data Labeling\n",
            "‚úÖ Data directory found: /content/drive/MyDrive/Machine_Learning/Sigatoka pics\n",
            "‚úÖ Output directory ready: /content/drive/MyDrive/Machine_Learning/Data Labeling\n",
            "‚úì Configuration loaded\n",
            "Data directory: /content/drive/MyDrive/Machine_Learning/Sigatoka pics\n",
            "Output directory: /content/drive/MyDrive/Machine_Learning/Data Labeling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMAGE QUALITY ASSESSOR** (cell 2)"
      ],
      "metadata": {
        "id": "tDytWFIuN5gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "class ImageQualityAssessor:\n",
        "\n",
        "\n",
        "    def __init__(self,\n",
        "                 min_resolution: Tuple[int, int] = (256, 256),\n",
        "                 max_blur_threshold: float = 100.0,\n",
        "                 min_brightness: int = 20,\n",
        "                 max_brightness: int = 240):\n",
        "        \"\"\"\n",
        "        Initialize quality assessor with thresholds.\n",
        "\n",
        "        Args:\n",
        "            min_resolution: Minimum (width, height) in pixels\n",
        "            max_blur_threshold: Laplacian variance threshold (lower = blurrier)\n",
        "            min_brightness: Minimum average brightness (0-255)\n",
        "            max_brightness: Maximum average brightness (0-255)\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If thresholds are invalid\n",
        "        \"\"\"\n",
        "        # Input validation (Senior-level)\n",
        "        if min_resolution[0] < 0 or min_resolution[1] < 0:\n",
        "            raise ValueError(\"Resolution must be positive\")\n",
        "        if max_blur_threshold < 0:\n",
        "            raise ValueError(\"Blur threshold must be positive\")\n",
        "        if not (0 <= min_brightness < max_brightness <= 255):\n",
        "            raise ValueError(\"Brightness thresholds must be in range [0, 255]\")\n",
        "\n",
        "        self.min_resolution = min_resolution\n",
        "        self.max_blur_threshold = max_blur_threshold\n",
        "        self.min_brightness = min_brightness\n",
        "        self.max_brightness = max_brightness\n",
        "\n",
        "        logger.info(f\"ImageQualityAssessor initialized with thresholds: {self.__dict__}\")\n",
        "\n",
        "    def check_blur(self, image: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Assess image blur using Laplacian variance.\n",
        "        Args:\n",
        "            image: Input image as numpy array\n",
        "\n",
        "        Returns:\n",
        "            Dict with 'score' (higher = sharper) and 'status' ('good'/'blurry'/'invalid')\n",
        "        \"\"\"\n",
        "        if image is None or not isinstance(image, np.ndarray) or image.size == 0:\n",
        "            logger.warning(\"Invalid image provided for blur check\")\n",
        "            return {\"score\": 0.0, \"status\": \"invalid\"}\n",
        "\n",
        "        try:\n",
        "            # Convert to grayscale if needed (Senior-level: Handle different formats)\n",
        "            if len(image.shape) == 3:\n",
        "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            elif len(image.shape) == 2:\n",
        "                gray = image\n",
        "            else:\n",
        "                logger.warning(f\"Unexpected image shape: {image.shape}\")\n",
        "                return {\"score\": 0.0, \"status\": \"invalid\"}\n",
        "\n",
        "            # Calculate Laplacian variance (Senior-level: Efficient computation)\n",
        "            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "            status = \"good\" if laplacian_var >= self.max_blur_threshold else \"blurry\"\n",
        "\n",
        "            return {\"score\": float(laplacian_var), \"status\": status}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in blur check: {e}\", exc_info=True)\n",
        "            return {\"score\": 0.0, \"status\": \"error\", \"error\": str(e)}\n",
        "\n",
        "    def check_brightness(self, image: np.ndarray) -> Dict[str, float]:\n",
        "        \"\"\"Assess image brightness\"\"\"\n",
        "        if image is None or image.size == 0:\n",
        "            return {\"score\": 0.0, \"status\": \"invalid\"}\n",
        "\n",
        "        if len(image.shape) == 3:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            gray = image\n",
        "\n",
        "        avg_brightness = np.mean(gray)\n",
        "\n",
        "        if avg_brightness < self.min_brightness:\n",
        "            status = \"too_dark\"\n",
        "        elif avg_brightness > self.max_brightness:\n",
        "            status = \"too_bright\"\n",
        "        else:\n",
        "            status = \"good\"\n",
        "\n",
        "        return {\"score\": float(avg_brightness), \"status\": status}\n",
        "\n",
        "    def check_resolution(self, image: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Check image resolution.\n",
        "        Args:\n",
        "            image: Input image as numpy array\n",
        "        Returns:\n",
        "            Dict with width, height, and status\n",
        "        \"\"\"\n",
        "        if image is None or not isinstance(image, np.ndarray) or image.size == 0:\n",
        "            return {\"width\": 0, \"height\": 0, \"status\": \"invalid\"}\n",
        "\n",
        "        try:\n",
        "            height, width = image.shape[:2]\n",
        "            min_w, min_h = self.min_resolution\n",
        "            status = \"good\" if width >= min_w and height >= min_h else \"too_small\"\n",
        "\n",
        "            return {\"width\": int(width), \"height\": int(height), \"status\": status}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in resolution check: {e}\", exc_info=True)\n",
        "            return {\"width\": 0, \"height\": 0, \"status\": \"error\", \"error\": str(e)}\n",
        "\n",
        "    def check_file_size(self, file_path: Path) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Check file size with proper error handling.\n",
        "        Args:\n",
        "            file_path: Path to file\n",
        "        Returns:\n",
        "            Dict with file size information\n",
        "        \"\"\"\n",
        "        if not isinstance(file_path, Path):\n",
        "            file_path = Path(file_path)\n",
        "\n",
        "        try:\n",
        "            if not file_path.exists():\n",
        "                logger.warning(f\"File not found: {file_path}\")\n",
        "                return {\"size_bytes\": 0, \"size_kb\": 0.0, \"size_mb\": 0.0, \"status\": \"file_not_found\"}\n",
        "\n",
        "            size_bytes = os.path.getsize(file_path)\n",
        "            size_kb = size_bytes / 1024\n",
        "            size_mb = size_kb / 1024\n",
        "\n",
        "            if size_kb < 50:\n",
        "                status = \"too_small\"\n",
        "            elif size_mb > 10:\n",
        "                status = \"too_large\"\n",
        "            else:\n",
        "                status = \"good\"\n",
        "\n",
        "            return {\n",
        "                \"size_bytes\": int(size_bytes),\n",
        "                \"size_kb\": round(size_kb, 2),\n",
        "                \"size_mb\": round(size_mb, 2),\n",
        "                \"status\": status\n",
        "            }\n",
        "        except OSError as e:\n",
        "            logger.error(f\"OS error checking file size for {file_path}: {e}\")\n",
        "            return {\"size_bytes\": 0, \"size_kb\": 0.0, \"size_mb\": 0.0, \"status\": f\"error: {str(e)}\"}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Unexpected error checking file size: {e}\", exc_info=True)\n",
        "            return {\"size_bytes\": 0, \"size_kb\": 0.0, \"size_mb\": 0.0, \"status\": f\"error: {str(e)}\"}\n",
        "\n",
        "    def assess_image(self, image_path: Path) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_path: Path to image file\n",
        "\n",
        "        Returns:\n",
        "            Dict with comprehensive quality metrics\n",
        "        \"\"\"\n",
        "        if not isinstance(image_path, Path):\n",
        "            image_path = Path(image_path)\n",
        "\n",
        "        results = {\n",
        "            \"image_path\": str(image_path),\n",
        "            \"file_exists\": False,\n",
        "            \"readable\": False,\n",
        "            \"overall_status\": \"unknown\"\n",
        "        }\n",
        "\n",
        "        if not image_path.exists():\n",
        "            logger.warning(f\"Image file not found: {image_path}\")\n",
        "            results[\"overall_status\"] = \"file_not_found\"\n",
        "            return results\n",
        "\n",
        "        results[\"file_exists\"] = True\n",
        "        file_size_info = self.check_file_size(image_path)\n",
        "        results.update(file_size_info)\n",
        "\n",
        "        try:\n",
        "            # Senior-level: Use cv2.IMREAD_UNCHANGED to preserve image properties\n",
        "            image = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n",
        "            if image is None:\n",
        "                logger.warning(f\"Cannot read image (may be corrupted): {image_path}\")\n",
        "                results[\"overall_status\"] = \"cannot_read\"\n",
        "                return results\n",
        "\n",
        "            results[\"readable\"] = True\n",
        "\n",
        "            # Perform all quality checks\n",
        "            resolution_info = self.check_resolution(image)\n",
        "            results.update(resolution_info)\n",
        "\n",
        "            blur_info = self.check_blur(image)\n",
        "            results[\"blur_score\"] = blur_info.get(\"score\", 0.0)\n",
        "            results[\"blur_status\"] = blur_info.get(\"status\", \"unknown\")\n",
        "\n",
        "            brightness_info = self.check_brightness(image)\n",
        "            results[\"brightness_score\"] = brightness_info.get(\"score\", 0.0)\n",
        "            results[\"brightness_status\"] = brightness_info.get(\"status\", \"unknown\")\n",
        "\n",
        "            # Aggregate issues (Senior-level: Structured issue tracking)\n",
        "            issues = []\n",
        "            if resolution_info.get(\"status\") != \"good\":\n",
        "                issues.append(\"resolution\")\n",
        "            if blur_info.get(\"status\") not in [\"good\", \"unknown\"]:\n",
        "                issues.append(\"blur\")\n",
        "            if brightness_info.get(\"status\") not in [\"good\", \"unknown\"]:\n",
        "                issues.append(\"brightness\")\n",
        "            if file_size_info.get(\"status\") != \"good\":\n",
        "                issues.append(\"file_size\")\n",
        "\n",
        "            if not issues:\n",
        "                results[\"overall_status\"] = \"good\"\n",
        "            else:\n",
        "                results[\"overall_status\"] = f\"issues: {', '.join(issues)}\"\n",
        "                results[\"issues\"] = issues\n",
        "\n",
        "            logger.debug(f\"Quality assessment complete for {image_path.name}: {results['overall_status']}\")\n",
        "\n",
        "        except cv2.error as e:\n",
        "            logger.error(f\"OpenCV error processing {image_path}: {e}\", exc_info=True)\n",
        "            results[\"overall_status\"] = f\"opencv_error: {str(e)}\"\n",
        "            results[\"error\"] = str(e)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Unexpected error assessing {image_path}: {e}\", exc_info=True)\n",
        "            results[\"overall_status\"] = f\"error: {str(e)}\"\n",
        "            results[\"error\"] = str(e)\n",
        "\n",
        "        return results\n",
        "\n",
        "logger.info(\"‚úì ImageQualityAssessor class loaded\")\n"
      ],
      "metadata": {
        "id": "QR6TBX0oMxXV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LABELING WORKFLOW** (cell 3)"
      ],
      "metadata": {
        "id": "zlbMm079OElJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class LabelingWorkflow:\n",
        "    \"\"\"Main workflow for creating labeled dataset\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_dir: Path,\n",
        "                 output_dir: Path,\n",
        "                 class_labels: Dict[str, str] = None,\n",
        "                 quality_thresholds: Dict = None):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.class_labels = class_labels or CLASS_LABELS\n",
        "        quality_thresholds = quality_thresholds or QUALITY_THRESHOLDS\n",
        "        self.quality_assessor = ImageQualityAssessor(**quality_thresholds)\n",
        "\n",
        "        # Create output structure\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        (self.output_dir / \"images\").mkdir(exist_ok=True)\n",
        "        (self.output_dir / \"labels\").mkdir(exist_ok=True)\n",
        "        (self.output_dir / \"metadata\").mkdir(exist_ok=True)\n",
        "\n",
        "    def extract_class_from_folder(self, folder_path: Path) -> Optional[str]:\n",
        "        \"\"\"Extract class label from folder name\"\"\"\n",
        "        folder_name = folder_path.name\n",
        "        for key, label in self.class_labels.items():\n",
        "            if key.lower() in folder_name.lower():\n",
        "                return label\n",
        "        return None\n",
        "\n",
        "    def extract_metadata(self, image_path: Path, class_label: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Extract comprehensive metadata for a single image.\n",
        "\n",
        "        Senior-level: Comprehensive metadata extraction with validation.\n",
        "\n",
        "        Args:\n",
        "            image_path: Path to image file\n",
        "            class_label: Class label for the image\n",
        "\n",
        "        Returns:\n",
        "            Dict with comprehensive metadata\n",
        "        \"\"\"\n",
        "        if not isinstance(image_path, Path):\n",
        "            image_path = Path(image_path)\n",
        "\n",
        "        metadata = {\n",
        "            \"image_path\": str(image_path),\n",
        "            \"class_label\": class_label,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"source_folder\": str(image_path.parent.name),\n",
        "            \"filename\": image_path.name\n",
        "        }\n",
        "\n",
        "        # Quality assessment\n",
        "        quality_result = self.quality_assessor.assess_image(image_path)\n",
        "\n",
        "        metadata.update({\n",
        "            \"width\": quality_result.get(\"width\", 0),\n",
        "            \"height\": quality_result.get(\"height\", 0),\n",
        "            \"file_size_kb\": round(quality_result.get(\"size_kb\", 0), 2),\n",
        "            \"file_size_mb\": round(quality_result.get(\"size_mb\", 0), 3),\n",
        "            \"blur_score\": round(quality_result.get(\"blur_score\", 0), 2),\n",
        "            \"brightness_score\": round(quality_result.get(\"brightness_score\", 0), 2),\n",
        "            \"quality_status\": quality_result.get(\"overall_status\", \"unknown\"),\n",
        "            \"blur_status\": quality_result.get(\"blur_status\", \"unknown\"),\n",
        "            \"brightness_status\": quality_result.get(\"brightness_status\", \"unknown\")\n",
        "        })\n",
        "\n",
        "        # Senior-level: Add issues list if present\n",
        "        if \"issues\" in quality_result:\n",
        "            metadata[\"quality_issues\"] = quality_result[\"issues\"]\n",
        "\n",
        "        return metadata\n",
        "\n",
        "    def process_stage_folder(self, stage_folder: Path) -> List[Dict[str, any]]:\n",
        "        \"\"\"Process all images in a stage folder\"\"\"\n",
        "        class_label = self.extract_class_from_folder(stage_folder)\n",
        "        if not class_label:\n",
        "            print(f\"‚ö† Warning: Could not determine class for {stage_folder}\")\n",
        "            return []\n",
        "\n",
        "        print(f\"\\nüìÅ Processing {stage_folder.name} -> Class: {class_label}\")\n",
        "\n",
        "        image_files = []\n",
        "        for ext in [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\"]:\n",
        "            image_files.extend(stage_folder.glob(ext))\n",
        "\n",
        "        if not image_files:\n",
        "            print(f\"  ‚ö† No images found in {stage_folder}\")\n",
        "            return []\n",
        "\n",
        "        metadata_list = []\n",
        "\n",
        "        # Senior-level: Progress bar for batch processing\n",
        "        for img_path in tqdm(image_files, desc=f\"Processing {class_label}\", leave=False):\n",
        "            try:\n",
        "                metadata = self.extract_metadata(img_path, class_label)\n",
        "                output_image_name = f\"{class_label}_{img_path.name}\"\n",
        "                output_image_path = self.output_dir / \"images\" / output_image_name\n",
        "\n",
        "                # Senior-level: Check if file already exists to avoid overwriting\n",
        "                if output_image_path.exists():\n",
        "                    logger.warning(f\"Output file already exists, skipping: {output_image_path}\")\n",
        "                    metadata[\"output_image_path\"] = str(output_image_path)\n",
        "                    metadata[\"output_image_name\"] = output_image_name\n",
        "                    metadata[\"status\"] = \"skipped_duplicate\"\n",
        "                    metadata_list.append(metadata)\n",
        "                    continue\n",
        "\n",
        "                shutil.copy2(img_path, output_image_path)\n",
        "                metadata[\"output_image_path\"] = str(output_image_path)\n",
        "                metadata[\"output_image_name\"] = output_image_name\n",
        "                metadata[\"status\"] = \"success\"\n",
        "                metadata_list.append(metadata)\n",
        "                logger.debug(f\"Processed: {img_path.name} -> {output_image_name}\")\n",
        "\n",
        "            except shutil.Error as e:\n",
        "                logger.error(f\"File operation error for {img_path.name}: {e}\")\n",
        "                metadata[\"error\"] = str(e)\n",
        "                metadata[\"status\"] = \"error\"\n",
        "                metadata_list.append(metadata)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Unexpected error processing {img_path.name}: {e}\", exc_info=True)\n",
        "                metadata = {\"image_path\": str(img_path), \"class_label\": class_label, \"error\": str(e), \"status\": \"error\"}\n",
        "                metadata_list.append(metadata)\n",
        "\n",
        "        return metadata_list\n",
        "\n",
        "    def generate_csv_labels(self, metadata_list: List[Dict[str, any]]) -> Path:\n",
        "        \"\"\"Generate CSV file with labels\"\"\"\n",
        "        csv_path = self.output_dir / \"labels\" / \"dataset_labels.csv\"\n",
        "\n",
        "        fieldnames = METADATA_FIELDS.copy()\n",
        "        fieldnames.extend([\"output_image_path\", \"output_image_name\"])\n",
        "\n",
        "        with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')\n",
        "            writer.writeheader()\n",
        "\n",
        "            for metadata in metadata_list:\n",
        "                row = {k: v for k, v in metadata.items() if k in fieldnames}\n",
        "                writer.writerow(row)\n",
        "\n",
        "        print(f\"\\n‚úì CSV labels saved: {csv_path}\")\n",
        "        return csv_path\n",
        "\n",
        "    def generate_json_labels(self, metadata_list: List[Dict[str, any]]) -> Path:\n",
        "        \"\"\"Generate JSON file with labels\"\"\"\n",
        "        json_path = self.output_dir / \"labels\" / \"dataset_labels.json\"\n",
        "\n",
        "        output_data = {\n",
        "            \"dataset_info\": {\n",
        "                \"total_images\": len(metadata_list),\n",
        "                \"classes\": list(set(m[\"class_label\"] for m in metadata_list)),\n",
        "                \"generated_at\": datetime.now().isoformat()\n",
        "            },\n",
        "            \"images\": metadata_list\n",
        "        }\n",
        "\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"‚úì JSON labels saved: {json_path}\")\n",
        "        return json_path\n",
        "\n",
        "    def run_workflow(self,\n",
        "                    generate_csv: bool = True,\n",
        "                    generate_json: bool = True) -> Dict[str, any]:\n",
        "        \"\"\"Run complete labeling workflow\"\"\"\n",
        "        print(\"=\"*60)\n",
        "        print(\"BANANA LEAF DATA LABELING WORKFLOW\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        stage_folders = [d for d in self.data_dir.iterdir()\n",
        "                        if d.is_dir() and any(key.lower() in d.name.lower()\n",
        "                                            for key in self.class_labels.keys())]\n",
        "\n",
        "        if not stage_folders:\n",
        "            print(f\"‚ö† No stage folders found in {self.data_dir}\")\n",
        "            return {\"error\": \"No stage folders found\"}\n",
        "\n",
        "        print(f\"\\nüìÇ Found {len(stage_folders)} stage folders\")\n",
        "\n",
        "        all_metadata = []\n",
        "        for stage_folder in sorted(stage_folders):\n",
        "            metadata_list = self.process_stage_folder(stage_folder)\n",
        "            all_metadata.extend(metadata_list)\n",
        "\n",
        "        if not all_metadata:\n",
        "            print(\"\\n‚ö† No images processed\")\n",
        "            return {\"error\": \"No images processed\"}\n",
        "\n",
        "        output_files = {}\n",
        "\n",
        "        if generate_csv:\n",
        "            csv_path = self.generate_csv_labels(all_metadata)\n",
        "            output_files[\"csv\"] = str(csv_path)\n",
        "\n",
        "        if generate_json:\n",
        "            json_path = self.generate_json_labels(all_metadata)\n",
        "            output_files[\"json\"] = str(json_path)\n",
        "\n",
        "        class_counts = {}\n",
        "        for metadata in all_metadata:\n",
        "            class_label = metadata.get(\"class_label\", \"unknown\")\n",
        "            class_counts[class_label] = class_counts.get(class_label, 0) + 1\n",
        "\n",
        "        summary = {\n",
        "            \"total_images\": len(all_metadata),\n",
        "            \"class_distribution\": class_counts,\n",
        "            \"output_files\": output_files,\n",
        "            \"output_directory\": str(self.output_dir)\n",
        "        }\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"WORKFLOW SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Total images processed: {summary['total_images']}\")\n",
        "        print(f\"\\nClass distribution:\")\n",
        "        for class_label, count in sorted(class_counts.items()):\n",
        "            print(f\"  {class_label}: {count}\")\n",
        "        print(f\"\\nOutput directory: {self.output_dir}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return summary\n",
        "\n",
        "print(\"‚úì LabelingWorkflow class loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb3e5VjuNXdl",
        "outputId": "6f0da668-031a-4e0d-a67f-3478ed073453"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì LabelingWorkflow class loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RUN WORKFLOW** (cell 4-5)"
      ],
      "metadata": {
        "id": "zd8EY14oOWC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_params = {\n",
        "    'min_resolution': QUALITY_THRESHOLDS.get('min_resolution', (256, 256)),\n",
        "    'max_blur_threshold': QUALITY_THRESHOLDS.get('max_blur_threshold', 100.0),\n",
        "    'min_brightness': QUALITY_THRESHOLDS.get('min_brightness', 20),\n",
        "    'max_brightness': QUALITY_THRESHOLDS.get('max_brightness', 240)\n",
        "}\n",
        "assessor = ImageQualityAssessor(**valid_params)\n",
        "\n",
        "# Example: Assess Stage1 images\n",
        "stage1_dir = DATA_DIR / \"Stage1\"\n",
        "if stage1_dir.exists():\n",
        "    image_files = list(stage1_dir.glob(\"*.jpg\"))[:5]  # First 5 images\n",
        "\n",
        "    print(\"Quality Assessment Results:\")\n",
        "    for img_path in image_files:\n",
        "        result = assessor.assess_image(img_path)\n",
        "        print(f\"\\n{img_path.name}:\")\n",
        "        print(f\"  Blur Score: {result.get('blur_score', 0):.2f} ({result.get('blur_status')})\")\n",
        "        print(f\"  Brightness: {result.get('brightness_score', 0):.2f} ({result.get('brightness_status')})\")\n",
        "        print(f\"  Resolution: {result.get('width')}x{result.get('height')}\")\n",
        "        print(f\"  Status: {result.get('overall_status')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNVOeGCnPFKh",
        "outputId": "aa70a9a0-549a-4221-fa0b-562e26f8192b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quality Assessment Results:\n",
            "\n",
            "IMG_20251122_094954.jpg:\n",
            "  Blur Score: 89.03 (blurry)\n",
            "  Brightness: 153.04 (good)\n",
            "  Resolution: 2296x4080\n",
            "  Status: issues: blur\n",
            "\n",
            "IMG_20251122_094743.jpg:\n",
            "  Blur Score: 409.67 (good)\n",
            "  Brightness: 158.37 (good)\n",
            "  Resolution: 2296x4080\n",
            "  Status: good\n",
            "\n",
            "IMG_20251122_090650.jpg:\n",
            "  Blur Score: 442.68 (good)\n",
            "  Brightness: 159.48 (good)\n",
            "  Resolution: 2296x4080\n",
            "  Status: good\n",
            "\n",
            "IMG_20251122_094849.jpg:\n",
            "  Blur Score: 287.10 (good)\n",
            "  Brightness: 156.73 (good)\n",
            "  Resolution: 2296x4080\n",
            "  Status: good\n",
            "\n",
            "IMG_20251122_093454.jpg:\n",
            "  Blur Score: 830.28 (good)\n",
            "  Brightness: 153.48 (good)\n",
            "  Resolution: 2296x4080\n",
            "  Status: good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Filter QUALITY_THRESHOLDS to only include parameters expected by ImageQualityAssessor\n",
        "    quality_params_for_assessor = {\n",
        "        'min_resolution': QUALITY_THRESHOLDS.get('min_resolution'),\n",
        "        'max_blur_threshold': QUALITY_THRESHOLDS.get('max_blur_threshold'),\n",
        "        'min_brightness': QUALITY_THRESHOLDS.get('min_brightness'),\n",
        "        'max_brightness': QUALITY_THRESHOLDS.get('max_brightness')\n",
        "    }\n",
        "    quality_params_for_assessor = {k: v for k, v in quality_params_for_assessor.items() if v is not None}\n",
        "\n",
        "    workflow = LabelingWorkflow(\n",
        "        data_dir=DATA_DIR,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        quality_thresholds=quality_params_for_assessor # Pass the filtered parameters\n",
        "    )\n",
        "\n",
        "    logger.info(\"Starting labeling workflow...\")\n",
        "    results = workflow.run_workflow(\n",
        "        generate_csv=True,\n",
        "        generate_json=True\n",
        "    )\n",
        "\n",
        "    if \"error\" in results:\n",
        "        logger.error(f\"Workflow failed: {results['error']}\")\n",
        "    else:\n",
        "        logger.info(f\"Workflow completed successfully. Processed {results.get('total_images', 0)} images.\")\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(f\"Fatal error in workflow: {e}\", exc_info=True)\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0a-vDV7OekD",
        "outputId": "b1ad559e-91de-4ce0-bee3-3bc066d60e81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "BANANA LEAF DATA LABELING WORKFLOW\n",
            "============================================================\n",
            "\n",
            "üìÇ Found 4 stage folders\n",
            "\n",
            "üìÅ Processing Stage1 -> Class: Stage1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Stage1:   0%|          | 0/13 [00:00<?, ?it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_094954.jpg\n",
            "Processing Stage1:   8%|‚ñä         | 1/13 [00:00<00:04,  2.54it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_094743.jpg\n",
            "Processing Stage1:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  3.62it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_090650.jpg\n",
            "Processing Stage1:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:02,  4.18it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_094849.jpg\n",
            "Processing Stage1:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:02,  4.44it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_093454.jpg\n",
            "Processing Stage1:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:01,  4.61it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_094825.jpg\n",
            "Processing Stage1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:01<00:02,  2.60it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_090944.jpg\n",
            "Processing Stage1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.01it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_094843.jpg\n",
            "Processing Stage1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:03<00:02,  1.68it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_094534.jpg\n",
            "Processing Stage1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:04<00:03,  1.32it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_093458.jpg\n",
            "Processing Stage1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:05<00:02,  1.44it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_095349.jpg\n",
            "Processing Stage1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:05<00:01,  1.38it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_094831.jpg\n",
            "Processing Stage1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:06<00:00,  1.38it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage1_IMG_20251122_090007.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing Stage2 -> Class: Stage2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Stage2:   0%|          | 0/13 [00:00<?, ?it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_091531.jpg\n",
            "Processing Stage2:   8%|‚ñä         | 1/13 [00:00<00:07,  1.67it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_093423.jpg\n",
            "Processing Stage2:  15%|‚ñà‚ñå        | 2/13 [00:01<00:07,  1.45it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_091044.jpg\n",
            "Processing Stage2:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:02<00:07,  1.30it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_090601.jpg\n",
            "Processing Stage2:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:02<00:06,  1.44it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_094939.jpg\n",
            "Processing Stage2:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:03<00:06,  1.17it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_091202.jpg\n",
            "Processing Stage2:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:04<00:05,  1.24it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_095026.jpg\n",
            "Processing Stage2:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:05<00:04,  1.46it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_094923.jpg\n",
            "Processing Stage2:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:05<00:03,  1.45it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_093659.jpg\n",
            "Processing Stage2:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:06<00:03,  1.26it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_095314.jpg\n",
            "Processing Stage2:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:07<00:02,  1.18it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_093425.jpg\n",
            "Processing Stage2:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:08<00:01,  1.25it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_095302.jpg\n",
            "Processing Stage2:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:09<00:00,  1.13it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage2_IMG_20251122_093905.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing Stage3 -> Class: Stage3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Stage3:   0%|          | 0/13 [00:00<?, ?it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_095212.jpg\n",
            "Processing Stage3:   8%|‚ñä         | 1/13 [00:00<00:07,  1.55it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_094036.jpg\n",
            "Processing Stage3:  15%|‚ñà‚ñå        | 2/13 [00:01<00:10,  1.05it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_092113.jpg\n",
            "Processing Stage3:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:03<00:10,  1.06s/it]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_093655.jpg\n",
            "Processing Stage3:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:03<00:07,  1.16it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_095213.jpg\n",
            "Processing Stage3:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:04<00:06,  1.23it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_093428.jpg\n",
            "Processing Stage3:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:04<00:05,  1.29it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_091556.jpg\n",
            "Processing Stage3:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:05<00:04,  1.28it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_094045.jpg\n",
            "Processing Stage3:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:06<00:03,  1.26it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_093251.jpg\n",
            "Processing Stage3:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:07<00:03,  1.13it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_092111.jpg\n",
            "Processing Stage3:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:08<00:02,  1.05it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_095345.jpg\n",
            "Processing Stage3:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:09<00:01,  1.11it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_091156.jpg\n",
            "Processing Stage3:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:10<00:00,  1.09it/s]WARNING:__main__:Output file already exists, skipping: /content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_094028.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing healthy -> Class: Healthy\n",
            "  ‚ö† No images found in /content/drive/MyDrive/Machine_Learning/Sigatoka pics/healthy\n",
            "\n",
            "‚úì CSV labels saved: /content/drive/MyDrive/Machine_Learning/Data Labeling/labels/dataset_labels.csv\n",
            "‚úì JSON labels saved: /content/drive/MyDrive/Machine_Learning/Data Labeling/labels/dataset_labels.json\n",
            "\n",
            "============================================================\n",
            "WORKFLOW SUMMARY\n",
            "============================================================\n",
            "Total images processed: 39\n",
            "\n",
            "Class distribution:\n",
            "  Stage1: 13\n",
            "  Stage2: 13\n",
            "  Stage3: 13\n",
            "\n",
            "Output directory: /content/drive/MyDrive/Machine_Learning/Data Labeling\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DISPLAY RESUTLS** (cell 6)"
      ],
      "metadata": {
        "id": "6g4MqOgzOaUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"error\" not in results:\n",
        "    # Load CSV to display\n",
        "    csv_path = Path(results[\"output_files\"][\"csv\"])\n",
        "    if csv_path.exists():\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"DATASET SUMMARY \")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"\\nüìä Total Images: {len(df)}\")\n",
        "\n",
        "        print(f\"\\nüìà Class Distribution:\")\n",
        "        class_dist = df[\"class_label\"].value_counts()\n",
        "        print(class_dist)\n",
        "        print(f\"   Balance ratio: {class_dist.max() / class_dist.min():.2f}x\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Quality Status Distribution:\")\n",
        "        quality_dist = df[\"quality_status\"].value_counts()\n",
        "        print(quality_dist)\n",
        "\n",
        "        # Senior-level: Statistical summary\n",
        "        print(f\"\\nüìê Image Statistics:\")\n",
        "        print(f\"   Average Resolution: {df['width'].mean():.0f}x{df['height'].mean():.0f}\")\n",
        "        print(f\"   Average Blur Score: {df['blur_score'].mean():.2f}\")\n",
        "        print(f\"   Average Brightness: {df['brightness_score'].mean():.2f}\")\n",
        "        print(f\"   Average File Size: {df['file_size_kb'].mean():.2f} KB\")\n",
        "\n",
        "        # Senior-level: Quality issues analysis\n",
        "        if \"quality_issues\" in df.columns:\n",
        "            print(f\"\\n‚ö†Ô∏è  Quality Issues:\")\n",
        "            issue_counts = df[\"quality_issues\"].value_counts()\n",
        "            print(issue_counts)\n",
        "\n",
        "        print(f\"\\nüìã Sample Data (first 5 rows):\")\n",
        "        display_cols = [\"output_image_name\", \"class_label\", \"width\", \"height\",\n",
        "                       \"blur_score\", \"brightness_score\", \"quality_status\"]\n",
        "        available_cols = [col for col in display_cols if col in df.columns]\n",
        "        print(df[available_cols].head().to_string())\n",
        "\n",
        "        print(f\"\\n‚úì Labels saved to: {csv_path}\")\n",
        "        print(f\"‚úì JSON saved to: {results['output_files']['json']}\")\n",
        "        print(f\"‚úì Log file: data_labeling.log\")\n",
        "\n",
        "        logger.info(\"Summary displayed successfully\")\n",
        "else:\n",
        "    error_msg = results.get('error', 'Unknown error')\n",
        "    logger.error(f\"Workflow error: {error_msg}\")\n",
        "    print(f\"‚ùå Error: {error_msg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIsO-cQ-O3v6",
        "outputId": "e8a49669-1a5b-48b4-c928-1e06ff7fb649"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DATASET SUMMARY \n",
            "============================================================\n",
            "\n",
            "üìä Total Images: 39\n",
            "\n",
            "üìà Class Distribution:\n",
            "class_label\n",
            "Stage1    13\n",
            "Stage2    13\n",
            "Stage3    13\n",
            "Name: count, dtype: int64\n",
            "   Balance ratio: 1.00x\n",
            "\n",
            "‚úÖ Quality Status Distribution:\n",
            "quality_status\n",
            "good            35\n",
            "issues: blur     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üìê Image Statistics:\n",
            "   Average Resolution: 2296x4080\n",
            "   Average Blur Score: 483.30\n",
            "   Average Brightness: 155.38\n",
            "   Average File Size: 3686.65 KB\n",
            "\n",
            "üìã Sample Data (first 5 rows):\n",
            "                output_image_name class_label  width  height  blur_score  brightness_score quality_status\n",
            "0  Stage1_IMG_20251122_094954.jpg      Stage1   2296    4080       89.03            153.04   issues: blur\n",
            "1  Stage1_IMG_20251122_094743.jpg      Stage1   2296    4080      409.67            158.37           good\n",
            "2  Stage1_IMG_20251122_090650.jpg      Stage1   2296    4080      442.68            159.48           good\n",
            "3  Stage1_IMG_20251122_094849.jpg      Stage1   2296    4080      287.10            156.73           good\n",
            "4  Stage1_IMG_20251122_093454.jpg      Stage1   2296    4080      830.28            153.48           good\n",
            "\n",
            "‚úì Labels saved to: /content/drive/MyDrive/Machine_Learning/Data Labeling/labels/dataset_labels.csv\n",
            "‚úì JSON saved to: /content/drive/MyDrive/Machine_Learning/Data Labeling/labels/dataset_labels.json\n",
            "‚úì Log file: data_labeling.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAIN SPLITTING** (cell 7-11)"
      ],
      "metadata": {
        "id": "fRqajbv4a38O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FINAL_DATASET_DIR = OUTPUT_DIR / 'final_dataset'\n",
        "IMAGE_SOURCE_DIR = OUTPUT_DIR / 'images'\n",
        "\n",
        "# Create the final_dataset directory if it doesn't exist\n",
        "FINAL_DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load the dataset labels into a pandas DataFrame\n",
        "labels_df = pd.read_csv(results['output_files']['csv'])\n",
        "\n",
        "print(f\"‚úì Imported train_test_split.\")\n",
        "print(f\"‚úì Final dataset directory defined: {FINAL_DATASET_DIR}\")\n",
        "print(f\"‚úì Image source directory defined: {IMAGE_SOURCE_DIR}\")\n",
        "print(f\"‚úì Labels DataFrame loaded with {len(labels_df)} entries.\")\n",
        "labels_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "VGj9Pce6bBZD",
        "outputId": "728e929b-94bd-4581-dc3e-e81cef3a0066"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Imported train_test_split.\n",
            "‚úì Final dataset directory defined: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset\n",
            "‚úì Image source directory defined: /content/drive/MyDrive/Machine_Learning/Data Labeling/images\n",
            "‚úì Labels DataFrame loaded with 39 entries.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          image_path class_label  width  \\\n",
              "0  /content/drive/MyDrive/Machine_Learning/Sigato...      Stage1   2296   \n",
              "1  /content/drive/MyDrive/Machine_Learning/Sigato...      Stage1   2296   \n",
              "2  /content/drive/MyDrive/Machine_Learning/Sigato...      Stage1   2296   \n",
              "3  /content/drive/MyDrive/Machine_Learning/Sigato...      Stage1   2296   \n",
              "4  /content/drive/MyDrive/Machine_Learning/Sigato...      Stage1   2296   \n",
              "\n",
              "   height  file_size_kb  blur_score  brightness_score quality_status  \\\n",
              "0    4080       2863.69       89.03            153.04   issues: blur   \n",
              "1    4080       3681.04      409.67            158.37           good   \n",
              "2    4080       3888.03      442.68            159.48           good   \n",
              "3    4080       3946.05      287.10            156.73           good   \n",
              "4    4080       4224.37      830.28            153.48           good   \n",
              "\n",
              "                    timestamp source_folder  \\\n",
              "0  2025-12-04T06:39:29.584440        Stage1   \n",
              "1  2025-12-04T06:39:29.978966        Stage1   \n",
              "2  2025-12-04T06:39:30.174332        Stage1   \n",
              "3  2025-12-04T06:39:30.368314        Stage1   \n",
              "4  2025-12-04T06:39:30.571829        Stage1   \n",
              "\n",
              "                                   output_image_path  \\\n",
              "0  /content/drive/MyDrive/Machine_Learning/Data L...   \n",
              "1  /content/drive/MyDrive/Machine_Learning/Data L...   \n",
              "2  /content/drive/MyDrive/Machine_Learning/Data L...   \n",
              "3  /content/drive/MyDrive/Machine_Learning/Data L...   \n",
              "4  /content/drive/MyDrive/Machine_Learning/Data L...   \n",
              "\n",
              "                output_image_name  \n",
              "0  Stage1_IMG_20251122_094954.jpg  \n",
              "1  Stage1_IMG_20251122_094743.jpg  \n",
              "2  Stage1_IMG_20251122_090650.jpg  \n",
              "3  Stage1_IMG_20251122_094849.jpg  \n",
              "4  Stage1_IMG_20251122_093454.jpg  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3cae0ef-5420-4eef-93a1-3e0bfdf2d025\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>class_label</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>file_size_kb</th>\n",
              "      <th>blur_score</th>\n",
              "      <th>brightness_score</th>\n",
              "      <th>quality_status</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>source_folder</th>\n",
              "      <th>output_image_path</th>\n",
              "      <th>output_image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Sigato...</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>2296</td>\n",
              "      <td>4080</td>\n",
              "      <td>2863.69</td>\n",
              "      <td>89.03</td>\n",
              "      <td>153.04</td>\n",
              "      <td>issues: blur</td>\n",
              "      <td>2025-12-04T06:39:29.584440</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Data L...</td>\n",
              "      <td>Stage1_IMG_20251122_094954.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Sigato...</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>2296</td>\n",
              "      <td>4080</td>\n",
              "      <td>3681.04</td>\n",
              "      <td>409.67</td>\n",
              "      <td>158.37</td>\n",
              "      <td>good</td>\n",
              "      <td>2025-12-04T06:39:29.978966</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Data L...</td>\n",
              "      <td>Stage1_IMG_20251122_094743.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Sigato...</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>2296</td>\n",
              "      <td>4080</td>\n",
              "      <td>3888.03</td>\n",
              "      <td>442.68</td>\n",
              "      <td>159.48</td>\n",
              "      <td>good</td>\n",
              "      <td>2025-12-04T06:39:30.174332</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Data L...</td>\n",
              "      <td>Stage1_IMG_20251122_090650.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Sigato...</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>2296</td>\n",
              "      <td>4080</td>\n",
              "      <td>3946.05</td>\n",
              "      <td>287.10</td>\n",
              "      <td>156.73</td>\n",
              "      <td>good</td>\n",
              "      <td>2025-12-04T06:39:30.368314</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Data L...</td>\n",
              "      <td>Stage1_IMG_20251122_094849.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Sigato...</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>2296</td>\n",
              "      <td>4080</td>\n",
              "      <td>4224.37</td>\n",
              "      <td>830.28</td>\n",
              "      <td>153.48</td>\n",
              "      <td>good</td>\n",
              "      <td>2025-12-04T06:39:30.571829</td>\n",
              "      <td>Stage1</td>\n",
              "      <td>/content/drive/MyDrive/Machine_Learning/Data L...</td>\n",
              "      <td>Stage1_IMG_20251122_093454.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3cae0ef-5420-4eef-93a1-3e0bfdf2d025')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3cae0ef-5420-4eef-93a1-3e0bfdf2d025 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3cae0ef-5420-4eef-93a1-3e0bfdf2d025');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-544b9971-b0d1-4fa3-93e2-4fb78a12c827\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-544b9971-b0d1-4fa3-93e2-4fb78a12c827')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-544b9971-b0d1-4fa3-93e2-4fb78a12c827 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df",
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 39,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"/content/drive/MyDrive/Machine_Learning/Sigatoka pics/Stage3/IMG_20251122_094045.jpg\",\n          \"/content/drive/MyDrive/Machine_Learning/Sigatoka pics/Stage3/IMG_20251122_095345.jpg\",\n          \"/content/drive/MyDrive/Machine_Learning/Sigatoka pics/Stage1/IMG_20251122_093454.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Stage1\",\n          \"Stage2\",\n          \"Stage3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2296,\n        \"max\": 2296,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4080,\n        \"max\": 4080,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4080\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_size_kb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 626.1430170974671,\n        \"min\": 2022.38,\n        \"max\": 4799.32,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          3940.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blur_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 359.8814537970032,\n        \"min\": 53.25,\n        \"max\": 1575.63,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          760.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brightness_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.921248555465414,\n        \"min\": 141.07,\n        \"max\": 183.43,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          145.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quality_status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"2025-12-04T06:39:52.794484\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_folder\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Stage1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"/content/drive/MyDrive/Machine_Learning/Data Labeling/images/Stage3_IMG_20251122_094045.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_image_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"Stage3_IMG_20251122_094045.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 42\n",
        "\n",
        "# 1. Split labels_df into training and temporary combined validation/test set\n",
        "train_df, val_test_df = train_test_split(\n",
        "    labels_df,\n",
        "    test_size=0.3,\n",
        "    random_state=random_state,\n",
        "    stratify=labels_df['class_label']\n",
        ")\n",
        "\n",
        "# 2. Further split val_test_df into validation and test sets\n",
        "val_df, test_df = train_test_split(\n",
        "    val_test_df,\n",
        "    test_size=0.5,\n",
        "    random_state=random_state,\n",
        "    stratify=val_test_df['class_label']\n",
        ")\n",
        "\n",
        "# 3. Print the number of samples in each resulting DataFrame\n",
        "print(f\"\\nDataset split summary:\")\n",
        "print(f\"  Training set: {len(train_df)} samples\")\n",
        "print(f\"  Validation set: {len(val_df)} samples\")\n",
        "print(f\"  Test set: {len(test_df)} samples\")\n",
        "\n",
        "print(f\"\\nClass distribution in Training set:\\n{train_df['class_label'].value_counts()}\\n\")\n",
        "print(f\"Class distribution in Validation set:\\n{val_df['class_label'].value_counts()}\\n\")\n",
        "print(f\"Class distribution in Test set:\\n{test_df['class_label'].value_counts()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8XrMUAFbOyi",
        "outputId": "9a7572fb-09fb-40a3-c824-a250fd49de8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset split summary:\n",
            "  Training set: 27 samples\n",
            "  Validation set: 6 samples\n",
            "  Test set: 6 samples\n",
            "\n",
            "Class distribution in Training set:\n",
            "class_label\n",
            "Stage2    9\n",
            "Stage1    9\n",
            "Stage3    9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class distribution in Validation set:\n",
            "class_label\n",
            "Stage3    2\n",
            "Stage1    2\n",
            "Stage2    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class distribution in Test set:\n",
            "class_label\n",
            "Stage1    2\n",
            "Stage3    2\n",
            "Stage2    2\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_types = ['train', 'validation', 'test']\n",
        "\n",
        "for split_type in split_types:\n",
        "    split_dir = FINAL_DATASET_DIR / split_type\n",
        "    split_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"‚úì Created directory: {split_dir}\")\n",
        "\n",
        "    # Create 'images' and 'labels' subdirectories within each split\n",
        "    images_dir = split_dir / 'images'\n",
        "    images_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"  ‚úì Created directory: {images_dir}\")\n",
        "\n",
        "    labels_dir = split_dir / 'labels'\n",
        "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"  ‚úì Created directory: {labels_dir}\")\n",
        "\n",
        "print(\"\\n‚úì Adjusted dataset directory structure created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62T1iCekbjL_",
        "outputId": "c885d628-56b1-4973-e358-028f258e97b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Created directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/train\n",
            "  ‚úì Created directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/train/images\n",
            "  ‚úì Created directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/train/labels\n",
            "‚úì Created directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/validation\n",
            "  ‚úì Created directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/validation/images\n",
            "  ‚úì Created directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/validation/labels\n",
            "‚úì Created directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/test\n",
            "  ‚úì Created directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/test/images\n",
            "  ‚úì Created directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/test/labels\n",
            "\n",
            "‚úì Adjusted dataset directory structure created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits_to_process = [\n",
        "    (train_df, 'train'),\n",
        "    (val_df, 'validation'),\n",
        "    (test_df, 'test')\n",
        "]\n",
        "\n",
        "for df_split, split_type in splits_to_process:\n",
        "    print(f\"\\nCopying images for {split_type} split...\")\n",
        "    for index, row in tqdm(df_split.iterrows(), total=len(df_split), desc=f\"Copying {split_type} images\"):\n",
        "        source_image_name = row['output_image_name']\n",
        "        # The class_label is implicitly part of the structure, but not needed for the image copy destination itself in this new structure\n",
        "\n",
        "        source_path = IMAGE_SOURCE_DIR / source_image_name\n",
        "        destination_path = FINAL_DATASET_DIR / split_type / 'images' / source_image_name\n",
        "\n",
        "        try:\n",
        "            shutil.copy2(source_path, destination_path)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Warning: Source file not found: {source_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error copying {source_image_name} to {destination_path}: {e}\")\n",
        "    print(f\"‚úì Finished copying images for {split_type} split.\")\n",
        "\n",
        "print(\"\\n‚úì All images copied to their respective split directories.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "308jgbG2bu5_",
        "outputId": "1ca160bd-513d-471d-b373-6bf8d667d660"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Copying images for train split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying train images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:14<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Finished copying images for train split.\n",
            "\n",
            "Copying images for validation split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying validation images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Finished copying images for validation split.\n",
            "\n",
            "Copying images for test split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying test images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Finished copying images for test split.\n",
            "\n",
            "‚úì All images copied to their respective split directories.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataframes = [\n",
        "    (train_df, 'train'),\n",
        "    (val_df, 'validation'),\n",
        "    (test_df, 'test')\n",
        "]\n",
        "\n",
        "for df, split_type in split_dataframes:\n",
        "    output_csv_path = FINAL_DATASET_DIR / split_type / 'labels' / f'{split_type}_labels.csv'\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"‚úì {split_type.capitalize()} labels saved to: {output_csv_path}\")\n",
        "\n",
        "print(\"\\n‚úì All split label CSVs generated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV0cRP6ebwH-",
        "outputId": "c8aba237-15e5-4276-c671-ea7889af21b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Train labels saved to: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/train/labels/train_labels.csv\n",
            "‚úì Validation labels saved to: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/validation/labels/validation_labels.csv\n",
            "‚úì Test labels saved to: /content/drive/MyDrive/Machine_Learning/Data Labeling/final_dataset/test/labels/test_labels.csv\n",
            "\n",
            "‚úì All split label CSVs generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA AUGMENTATION** (cell 12-13)"
      ],
      "metadata": {
        "id": "fUcfmyx_ccdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUGMENTATION_CONFIG = {\n",
        "    'rotation_range': 15,      # Rotate ¬±15 degrees\n",
        "    'flip_horizontal': True,   # Horizontal flip\n",
        "    'brightness_range': 0.2,   # Brightness ¬±20%\n",
        "    'contrast_range': 0.2,     # Contrast ¬±20%\n",
        "    'samples_per_image': 2     # Generate 2 augmented images per original\n",
        "}\n",
        "\n",
        "# Output directory for augmented images\n",
        "AUGMENTED_DIR = OUTPUT_DIR / 'augmented_dataset'\n",
        "\n",
        "def augment_image(image_path, output_dir, aug_id):\n",
        "    \"\"\"Generate augmented image - returns new filename\"\"\"\n",
        "    # Read image\n",
        "    img = cv2.imread(str(image_path))\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    augmented = img.copy()\n",
        "\n",
        "    # Random rotation\n",
        "    if random.random() < 0.5:\n",
        "        angle = random.uniform(-AUGMENTATION_CONFIG['rotation_range'],\n",
        "                              AUGMENTATION_CONFIG['rotation_range'])\n",
        "        h, w = augmented.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "        augmented = cv2.warpAffine(augmented, M, (w, h),\n",
        "                                   borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "    # Horizontal flip\n",
        "    if AUGMENTATION_CONFIG['flip_horizontal'] and random.random() < 0.5:\n",
        "        augmented = cv2.flip(augmented, 1)\n",
        "\n",
        "    # Brightness adjustment\n",
        "    if random.random() < 0.5:\n",
        "        brightness = random.uniform(1 - AUGMENTATION_CONFIG['brightness_range'],\n",
        "                                    1 + AUGMENTATION_CONFIG['brightness_range'])\n",
        "        augmented = cv2.convertScaleAbs(augmented, alpha=1, beta=(brightness-1)*50)\n",
        "\n",
        "    # Contrast adjustment\n",
        "    if random.random() < 0.5:\n",
        "        contrast = random.uniform(1 - AUGMENTATION_CONFIG['contrast_range'],\n",
        "                                  1 + AUGMENTATION_CONFIG['contrast_range'])\n",
        "        augmented = cv2.convertScaleAbs(augmented, alpha=contrast, beta=0)\n",
        "\n",
        "    # Save augmented image\n",
        "    original_name = image_path.stem\n",
        "    new_filename = f\"{original_name}_aug{aug_id}{image_path.suffix}\"\n",
        "    output_path = output_dir / new_filename\n",
        "    cv2.imwrite(str(output_path), augmented)\n",
        "\n",
        "    return new_filename\n",
        "print(f\"\\nüìÅ Augmented dataset directory: {AUGMENTED_DIR}\")\n",
        "print(f\"   Samples per image: {AUGMENTATION_CONFIG['samples_per_image']}\")\n",
        "print(f\"   Rotation: ¬±{AUGMENTATION_CONFIG['rotation_range']}¬∞\")\n",
        "print(f\"   Horizontal flip: {AUGMENTATION_CONFIG['flip_horizontal']}\")\n",
        "print(f\"   Brightness: ¬±{int(AUGMENTATION_CONFIG['brightness_range']*100)}%\")\n",
        "print(f\"   Contrast: ¬±{int(AUGMENTATION_CONFIG['contrast_range']*100)}%\")"
      ],
      "metadata": {
        "id": "fVsq2tr8dHiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load split CSVs\n",
        "train_csv = FINAL_DATASET_DIR / 'train' / 'labels' / 'train_labels.csv'\n",
        "val_csv = FINAL_DATASET_DIR / 'validation' / 'labels' / 'validation_labels.csv'\n",
        "test_csv = FINAL_DATASET_DIR / 'test' / 'labels' / 'test_labels.csv'\n",
        "\n",
        "print(f\"   Train: {train_csv.exists()}\")\n",
        "print(f\"   Validation: {val_csv.exists()}\")\n",
        "print(f\"   Test: {test_csv.exists()}\")\n",
        "\n",
        "if not all([train_csv.exists(), val_csv.exists(), test_csv.exists()]):\n",
        "    print(\"\\n‚ùå ERROR: Split CSVs not found!\")\n",
        "    print(\"   Please run Cells 8-11 (data splitting) first\")\n",
        "else:\n",
        "    print(\"‚úÖ All CSVs found!\")\n",
        "\n",
        "# ONLY AUGMENT TRAINING DATA\n",
        "\n",
        "# Load training data\n",
        "train_df = pd.read_csv(train_csv)\n",
        "\n",
        "# Create augmented directory for training\n",
        "train_aug_dir = AUGMENTED_DIR / 'train' / 'images'\n",
        "train_aug_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "augmented_count = 0\n",
        "augmented_records = []\n",
        "\n",
        "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Augmenting training images\"):\n",
        "    try:\n",
        "        source_image_path = Path(row['output_image_path'])\n",
        "        class_label = row['class_label']  # Same label for augmented image\n",
        "\n",
        "        if not source_image_path.exists():\n",
        "            continue\n",
        "\n",
        "        # Generate augmented images\n",
        "        for aug_id in range(AUGMENTATION_CONFIG['samples_per_image']):\n",
        "            new_filename = augment_image(\n",
        "                source_image_path,\n",
        "                train_aug_dir,\n",
        "                aug_id\n",
        "            )\n",
        "\n",
        "            if new_filename:\n",
        "                # Augmented image gets SAME class label (whole image annotation)\n",
        "                augmented_records.append({\n",
        "                    'output_image_name': new_filename,\n",
        "                    'class_label': class_label,  # SAME LABEL\n",
        "                    'output_image_path': str(train_aug_dir / new_filename),\n",
        "                    'width': row.get('width', ''),\n",
        "                    'height': row.get('height', ''),\n",
        "                    'file_size_kb': row.get('file_size_kb', ''),\n",
        "                    'source_folder': row.get('source_folder', ''),\n",
        "                    'is_augmented': True,\n",
        "                    'original_image': row['output_image_name']\n",
        "                })\n",
        "                augmented_count += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error augmenting {row.get('output_image_name', 'unknown')}: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Training augmentation:\")\n",
        "print(f\"   Original images: {len(train_df)}\")\n",
        "print(f\"   Augmented images: {augmented_count}\")\n",
        "print(f\"   Total training images: {len(train_df) + augmented_count}\")\n",
        "\n",
        "# Combine original training + augmented training\n",
        "if augmented_records:\n",
        "    aug_df = pd.DataFrame(augmented_records)\n",
        "    combined_train_df = pd.concat([train_df, aug_df], ignore_index=True)\n",
        "else:\n",
        "    combined_train_df = train_df\n",
        "\n",
        "# Save combined training CSV (original + augmented)\n",
        "combined_train_csv = FINAL_DATASET_DIR / 'train' / 'labels' / 'train_labels_with_augmentation.csv'\n",
        "combined_train_df.to_csv(combined_train_csv, index=False)\n",
        "\n",
        "print(f\"\\n Combined training CSV saved: {combined_train_csv}\")\n",
        "\n",
        "# Validation and Test remain unchanged\n",
        "val_df = pd.read_csv(val_csv)\n",
        "test_df = pd.read_csv(test_csv)\n",
        "\n",
        "print(f\"\\nüìä Final dataset summary:\")\n",
        "print(f\"   Training (with augmentation): {len(combined_train_df)} images\")\n",
        "print(f\"   Validation (original only): {len(val_df)} images\")\n",
        "print(f\"   Test (original only): {len(test_df)} images\")\n",
        "print(f\"   Total: {len(combined_train_df) + len(val_df) + len(test_df)} images\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\" DATA AUGMENTATION COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìÅ Augmented images: {AUGMENTED_DIR / 'train'}\")"
      ],
      "metadata": {
        "id": "DEUOf-eidnNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YOLO FORMAT** (cell 14-16)"
      ],
      "metadata": {
        "id": "cKzubjVqDDgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YOLO_CLASSIFICATION_DIR = OUTPUT_DIR / 'yolo_classification_dataset'\n",
        "\n",
        "# Create YOLO classification structure\n",
        "yolo_train_dir = YOLO_CLASSIFICATION_DIR / 'train'\n",
        "yolo_val_dir = YOLO_CLASSIFICATION_DIR / 'validation'\n",
        "yolo_test_dir = YOLO_CLASSIFICATION_DIR / 'test'\n",
        "\n",
        "\n",
        "for split_dir in [yolo_train_dir, yolo_val_dir, yolo_test_dir]:\n",
        "    split_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\n‚úÖ YOLO classification dataset directory: {YOLO_CLASSIFICATION_DIR}\")\n",
        "train_csv = FINAL_DATASET_DIR / 'train' / 'labels' / 'train_labels_with_augmentation.csv'\n",
        "val_csv = FINAL_DATASET_DIR / 'validation' / 'labels' / 'validation_labels_with_augmentation.csv'\n",
        "test_csv = FINAL_DATASET_DIR / 'test' / 'labels' / 'test_labels_with_augmentation.csv'\n",
        "\n",
        "# Fallback to original CSVs if augmented don't exist\n",
        "if not train_csv.exists():\n",
        "    train_csv = FINAL_DATASET_DIR / 'train' / 'labels' / 'train_labels.csv'\n",
        "if not val_csv.exists():\n",
        "    val_csv = FINAL_DATASET_DIR / 'validation' / 'labels' / 'validation_labels.csv'\n",
        "if not test_csv.exists():\n",
        "    test_csv = FINAL_DATASET_DIR / 'test' / 'labels' / 'test_labels.csv'\n",
        "\n",
        "print(f\"\\n Loading split CSVs...\")\n",
        "print(f\"   Train: {train_csv.exists()}\")\n",
        "print(f\"   Validation: {val_csv.exists()}\")\n",
        "print(f\"   Test: {test_csv.exists()}\")\n",
        "\n",
        "\n",
        "if not all([train_csv.exists(), val_csv.exists(), test_csv.exists()]):\n",
        "    print(\"\\n ERROR: Split CSVs not found!\")\n",
        "    print(\"   Please run Cells 7-11 (data splitting) first\")\n",
        "else:\n",
        "    print(\"All split CSVs found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LElYmKCqDHTD",
        "outputId": "f3b20254-3de7-4266-dc9a-3d8825b1d23a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ YOLO classification dataset directory: /content/drive/MyDrive/Machine_Learning/Data Labeling/yolo_classification_dataset\n",
            "\n",
            "üìÇ Loading split CSVs...\n",
            "   Train: True\n",
            "   Validation: True\n",
            "   Test: True\n",
            "‚úÖ All split CSVs found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define splits mapping\n",
        "splits = {\n",
        "    'train': (train_csv, yolo_train_dir),\n",
        "    'validation': (val_csv, yolo_val_dir),\n",
        "    'test': (test_csv, yolo_test_dir)\n",
        "}\n",
        "\n",
        "# Get all unique classes from all splits\n",
        "all_classes = set()\n",
        "for split_name, (csv_path, _) in splits.items():\n",
        "    if csv_path.exists():\n",
        "        df = pd.read_csv(csv_path)\n",
        "        all_classes.update(df['class_label'].unique())\n",
        "\n",
        "# Sort classes for consistent mapping\n",
        "# Order: Healthy, Stage1, Stage2, Stage3, Stage4, Stage5, Stage6\n",
        "sorted_classes = sorted(list(all_classes))\n",
        "class_to_id = {cls: idx for idx, cls in enumerate(sorted_classes)}\n",
        "id_to_class = {idx: cls for cls, idx in class_to_id.items()}\n",
        "\n",
        "print(f\"\\nClasses found: {sorted_classes}\")\n",
        "print(f\"\\nClass to ID mapping:\")\n",
        "for cls, idx in class_to_id.items():\n",
        "    print(f\"   {idx}: {cls}\")\n",
        "\n",
        "# Process each split\n",
        "for split_name, (csv_path, yolo_dir) in splits.items():\n",
        "    if not csv_path.exists():\n",
        "        continue\n",
        "\n",
        "    print(f\" Processing {split_name.upper()} split...\")\n",
        "\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Copy images and organize by class\n",
        "    copied_count = 0\n",
        "    skipped_count = 0\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {split_name}\"):\n",
        "        try:\n",
        "            # Get image path and class from CSV\n",
        "            source_image_path = Path(row['output_image_path'])\n",
        "            class_label = row['class_label']  # Healthy, Stage1, Stage2, etc.\n",
        "\n",
        "            # Create class directory in YOLO format\n",
        "            # YOLO classification: images organized by class name\n",
        "            class_dir = yolo_dir / class_label\n",
        "            class_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            # Copy image to class directory\n",
        "            if source_image_path.exists():\n",
        "                dest_image_path = class_dir / source_image_path.name\n",
        "                shutil.copy2(source_image_path, dest_image_path)\n",
        "                copied_count += 1\n",
        "            else:\n",
        "                skipped_count += 1\n",
        "                logger.warning(f\"Image not found: {source_image_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing {row.get('output_image_name', 'unknown')}: {e}\")\n",
        "            skipped_count += 1\n",
        "\n",
        "    print(f\"\\n {split_name.capitalize()} split:\")\n",
        "    print(f\"   Copied: {copied_count} images\")\n",
        "    print(f\"   Skipped: {skipped_count} images\")\n",
        "\n",
        "    # Show class distribution\n",
        "    class_counts = df['class_label'].value_counts()\n",
        "    print(f\"\\n   Class distribution:\")\n",
        "    for cls, count in class_counts.items():\n",
        "        print(f\"      {cls}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oESpW6DIEZht",
        "outputId": "80c25f8c-4248-4ff0-8972-30005dd9d023"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classes found: ['Stage1', 'Stage2', 'Stage3']\n",
            "\n",
            "Class to ID mapping:\n",
            "   0: Stage1\n",
            "   1: Stage2\n",
            "   2: Stage3\n",
            "üì¶ Processing TRAIN split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:00<00:00, 36.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Train split:\n",
            "   Copied: 27 images\n",
            "   Skipped: 0 images\n",
            "\n",
            "   Class distribution:\n",
            "      Stage2: 9\n",
            "      Stage1: 9\n",
            "      Stage3: 9\n",
            "üì¶ Processing VALIDATION split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 35.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Validation split:\n",
            "   Copied: 6 images\n",
            "   Skipped: 0 images\n",
            "\n",
            "   Class distribution:\n",
            "      Stage3: 2\n",
            "      Stage1: 2\n",
            "      Stage2: 2\n",
            "üì¶ Processing TEST split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Test split:\n",
            "   Copied: 6 images\n",
            "   Skipped: 0 images\n",
            "\n",
            "   Class distribution:\n",
            "      Stage1: 2\n",
            "      Stage3: 2\n",
            "      Stage2: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create YOLO dataset.yaml file\n",
        "yolo_yaml_path = YOLO_CLASSIFICATION_DIR / 'dataset.yaml'\n",
        "\n",
        "# YOLO classification configuration\n",
        "yolo_config = {\n",
        "    'path': str(YOLO_CLASSIFICATION_DIR.absolute()),\n",
        "    'train': 'train',\n",
        "    'val': 'validation',\n",
        "    'test': 'test',\n",
        "    'names': id_to_class,  # {0: 'Healthy', 1: 'Stage1', 2: 'Stage2', ...}\n",
        "    'nc': len(sorted_classes)  # Number of classes\n",
        "}\n",
        "\n",
        "with open(yolo_yaml_path, 'w') as f:\n",
        "    yaml.dump(yolo_config, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print(f\"\\nYAML file created: {yolo_yaml_path}\")\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"   Path: {yolo_config['path']}\")\n",
        "print(f\"   Train: {yolo_config['train']}\")\n",
        "print(f\"   Validation: {yolo_config['val']}\")\n",
        "print(f\"   Test: {yolo_config['test']}\")\n",
        "print(f\"   Number of classes: {yolo_config['nc']}\")\n",
        "print(f\"   Classes: {list(yolo_config['names'].values())}\")\n",
        "\n",
        "with open(yolo_yaml_path, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "for split_name in ['train', 'validation', 'test']:\n",
        "    split_dir = YOLO_CLASSIFICATION_DIR / split_name\n",
        "    if split_dir.exists():\n",
        "        print(f\"\\nüìÇ {split_name.upper()}:\")\n",
        "        class_dirs = [d for d in split_dir.iterdir() if d.is_dir()]\n",
        "        total_images = 0\n",
        "\n",
        "        for class_dir in sorted(class_dirs):\n",
        "            images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.JPG')) + \\\n",
        "                     list(class_dir.glob('*.png')) + list(class_dir.glob('*.PNG'))\n",
        "            total_images += len(images)\n",
        "            print(f\"   {class_dir.name}: {len(images)} images\")\n",
        "\n",
        "        print(f\"   Total: {total_images} images\")\n",
        "\n",
        "print(f\"\\nüìÅ Dataset location: {YOLO_CLASSIFICATION_DIR}\")\n",
        "print(f\"   Config file: {yolo_yaml_path}\")\n",
        "print(f\"\\n Next step: Train YOLO classification model\")\n",
        "print(f\"   Use: model = YOLO('yolov8n-cls.pt')  # or yolov8s-cls.pt, yolov8m-cls.pt\")\n",
        "print(f\"   model.train(data='{yolo_yaml_path}', epochs=100)\")\n",
        "print(f\"   Dataset config: {yolo_yaml_path}\")\n",
        "print(f\"   Dataset location: {YOLO_CLASSIFICATION_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtpIkcQFEwcH",
        "outputId": "8d075fa0-ba0d-41ab-a852-3b08e8e0b653"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ YAML file created: /content/drive/MyDrive/Machine_Learning/Data Labeling/yolo_classification_dataset/dataset.yaml\n",
            "\n",
            "Configuration:\n",
            "   Path: /content/drive/MyDrive/Machine_Learning/Data Labeling/yolo_classification_dataset\n",
            "   Train: train\n",
            "   Validation: validation\n",
            "   Test: test\n",
            "   Number of classes: 3\n",
            "   Classes: ['Stage1', 'Stage2', 'Stage3']\n",
            "path: /content/drive/MyDrive/Machine_Learning/Data Labeling/yolo_classification_dataset\n",
            "train: train\n",
            "val: validation\n",
            "test: test\n",
            "names:\n",
            "  0: Stage1\n",
            "  1: Stage2\n",
            "  2: Stage3\n",
            "nc: 3\n",
            "\n",
            "\n",
            "üìÇ TRAIN:\n",
            "   Stage1: 9 images\n",
            "   Stage2: 9 images\n",
            "   Stage3: 9 images\n",
            "   Total: 27 images\n",
            "\n",
            "üìÇ VALIDATION:\n",
            "   Stage1: 2 images\n",
            "   Stage2: 2 images\n",
            "   Stage3: 2 images\n",
            "   Total: 6 images\n",
            "\n",
            "üìÇ TEST:\n",
            "   Stage1: 2 images\n",
            "   Stage2: 2 images\n",
            "   Stage3: 2 images\n",
            "   Total: 6 images\n",
            "\n",
            "üìÅ Dataset location: /content/drive/MyDrive/Machine_Learning/Data Labeling/yolo_classification_dataset\n",
            "üìù Config file: /content/drive/MyDrive/Machine_Learning/Data Labeling/yolo_classification_dataset/dataset.yaml\n",
            "\n",
            "üöÄ Next step: Train YOLO classification model\n",
            "   Use: model = YOLO('yolov8n-cls.pt')  # or yolov8s-cls.pt, yolov8m-cls.pt\n",
            "   model.train(data='/content/drive/MyDrive/Machine_Learning/Data Labeling/yolo_classification_dataset/dataset.yaml', epochs=100)\n",
            "   Dataset config: /content/drive/MyDrive/Machine_Learning/Data Labeling/yolo_classification_dataset/dataset.yaml\n",
            "   Dataset location: /content/drive/MyDrive/Machine_Learning/Data Labeling/yolo_classification_dataset\n"
          ]
        }
      ]
    }
  ]
}