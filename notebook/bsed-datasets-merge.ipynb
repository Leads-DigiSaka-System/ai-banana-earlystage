{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14068645,"sourceType":"datasetVersion","datasetId":8954975},{"sourceId":14069111,"sourceType":"datasetVersion","datasetId":8955322}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\nimport shutil\n\n# First dataset\ndataset_path = '/kaggle/input/bsed-datasets-v1/kaggle/working/Data Labeling/yolo_classification_dataset'\n\nprint(\"=\"*60)\nprint(\"üìä ANALYZING: YOLO CLASSIFICATION DATASET\")\nprint(\"=\"*60)\n\n# Create a working copy in writable directory\nworking_dir = Path('/kaggle/working')\ndataset_copy_dir = working_dir / 'yolo_classification_dataset'\n\n# Copy the dataset to working directory if not already copied\nif not dataset_copy_dir.exists():\n    print(f\"üìÅ Copying dataset to {dataset_copy_dir}...\")\n    shutil.copytree(dataset_path, dataset_copy_dir)\n    print(\"‚úÖ Dataset copied to working directory\")\nelse:\n    print(\"‚úÖ Using existing copy in working directory\")\n\n# Now use the copy\ndata_yaml_path = dataset_copy_dir / 'data.yaml'\n\n# Load data.yaml\nwith open(data_yaml_path, 'r') as file:\n    data_config = yaml.safe_load(file)\n\nprint(f\"\\nNumber of classes: {data_config['nc']}\")\nprint(f\"Class names: {data_config['names']}\")\n\n# Update paths in the working copy\nif 'train' in data_config:\n    # Fix path relative to current location\n    train_relative = data_config['train'].replace('../', '')\n    train_path = dataset_copy_dir / train_relative\n    data_config['train'] = str(train_path)\n    \nif 'val' in data_config:\n    val_relative = data_config['val'].replace('../', '')\n    val_path = dataset_copy_dir / val_relative\n    data_config['val'] = str(val_path)\n    \nif 'test' in data_config:\n    test_relative = data_config['test'].replace('../', '')\n    test_path = dataset_copy_dir / test_relative\n    data_config['test'] = str(test_path)\n\n# Count images\ntrain_img_path = Path(data_config['train'])\nval_img_path = Path(data_config['val'])\n\ntrain_images = len(list(train_img_path.glob('*.jpg'))) + len(list(train_img_path.glob('*.png')))\nval_images = len(list(val_img_path.glob('*.jpg'))) + len(list(val_img_path.glob('*.png')))\n\nif 'test' in data_config:\n    test_img_path = Path(data_config['test'])\n    test_images = len(list(test_img_path.glob('*.jpg'))) + len(list(test_img_path.glob('*.png')))\nelse:\n    test_images = 0\n\nprint(f\"\\nüìà Dataset Statistics:\")\nprint(f\"Training images: {train_images}\")\nprint(f\"Validation images: {val_images}\")\nprint(f\"Test images: {test_images}\")\n\n# Update and save yaml - Now it's writable!\ndata_config['path'] = str(dataset_copy_dir)\nwith open(data_yaml_path, 'w') as f:\n    yaml.dump(data_config, f, default_flow_style=False)\n\nprint(f\"\\n‚úÖ Dataset configuration saved to: {data_yaml_path}\")\nprint(f\"Working directory: {dataset_copy_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\nimport shutil\n\n# First dataset\ndataset_path = '/kaggle/input/roboflow-datasets/kaggle/working/Black-Sigatoka-4'\n\nprint(\"=\"*60)\nprint(\"üìä ANALYZING: YOLO CLASSIFICATION DATASET\")\nprint(\"=\"*60)\n\n# Create a working copy in writable directory\nworking_dir = Path('/kaggle/working')\ndataset_copy_dir = working_dir / 'Black-Sigatoka-4'\n\n# Copy the dataset to working directory if not already copied\nif not dataset_copy_dir.exists():\n    print(f\"üìÅ Copying dataset to {dataset_copy_dir}...\")\n    shutil.copytree(dataset_path, dataset_copy_dir)\n    print(\"‚úÖ Dataset copied to working directory\")\nelse:\n    print(\"‚úÖ Using existing copy in working directory\")\n\n# Now use the copy\ndata_yaml_path = dataset_copy_dir / 'data.yaml'\n\n# Load data.yaml\nwith open(data_yaml_path, 'r') as file:\n    data_config = yaml.safe_load(file)\n\nprint(f\"\\nNumber of classes: {data_config['nc']}\")\nprint(f\"Class names: {data_config['names']}\")\n\n# Update paths in the working copy\nif 'train' in data_config:\n    # Fix path relative to current location\n    train_relative = data_config['train'].replace('../', '')\n    train_path = dataset_copy_dir / train_relative\n    data_config['train'] = str(train_path)\n    \nif 'val' in data_config:\n    val_relative = data_config['val'].replace('../', '')\n    val_path = dataset_copy_dir / val_relative\n    data_config['val'] = str(val_path)\n    \nif 'test' in data_config:\n    test_relative = data_config['test'].replace('../', '')\n    test_path = dataset_copy_dir / test_relative\n    data_config['test'] = str(test_path)\n\n# Count images\ntrain_img_path = Path(data_config['train'])\nval_img_path = Path(data_config['val'])\n\ntrain_images = len(list(train_img_path.glob('*.jpg'))) + len(list(train_img_path.glob('*.png')))\nval_images = len(list(val_img_path.glob('*.jpg'))) + len(list(val_img_path.glob('*.png')))\n\nif 'test' in data_config:\n    test_img_path = Path(data_config['test'])\n    test_images = len(list(test_img_path.glob('*.jpg'))) + len(list(test_img_path.glob('*.png')))\nelse:\n    test_images = 0\n\nprint(f\"\\nüìà Dataset Statistics:\")\nprint(f\"Training images: {train_images}\")\nprint(f\"Validation images: {val_images}\")\nprint(f\"Test images: {test_images}\")\n\n# Update and save yaml - Now it's writable!\ndata_config['path'] = str(dataset_copy_dir)\nwith open(data_yaml_path, 'w') as f:\n    yaml.dump(data_config, f, default_flow_style=False)\n\nprint(f\"\\n‚úÖ Dataset configuration saved to: {data_yaml_path}\")\nprint(f\"Working directory: {dataset_copy_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **COMBINE DATASETS WITH CLASS MAPPING**","metadata":{}},{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\nimport shutil\nfrom tqdm import tqdm\nimport os\nimport re\n\nprint(\"=\"*80)\nprint(\"üîÑ COMBINING BSED AND ROBoFLOW DATASETS\")\nprint(\"=\"*80)\n\n# ============================================================================\n# CLASS MAPPING CONFIGURATION\n# ============================================================================\n# Final classification scheme (from data-labeling-classification.ipynb)\nFINAL_CLASS_ORDER = ['Healthy', 'Stage1', 'Stage2', 'Stage3', 'Stage4', 'Stage5', 'Stage6']\n\n# Roboflow class mapping: actual class names ‚Üí final class names\n# Based on actual Roboflow dataset class names\nROBOFLOW_CLASS_NAME_MAPPING = {\n    'Functional': 'Healthy',   # Functional ‚Üí Healthy\n    'Mild': 'Stage4',           # Mild ‚Üí Stage4\n    'Moderate': 'Stage5',       # Moderate ‚Üí Stage5\n    'Severe': 'Stage6'          # Severe ‚Üí Stage6\n}\n\n# Also map numeric IDs (used in label files) ‚Üí class names\n# Label files use numeric IDs (0, 1, 2, 3) which correspond to:\nROBOFLOW_CLASS_ID_MAPPING = {\n    '0': 'Functional',   # Label file ID 0 ‚Üí Functional ‚Üí Healthy\n    '1': 'Mild',          # Label file ID 1 ‚Üí Mild ‚Üí Stage4\n    '2': 'Moderate',       # Label file ID 2 ‚Üí Moderate ‚Üí Stage5\n    '3': 'Severe'          # Label file ID 3 ‚Üí Severe ‚Üí Stage6\n}\n\n# Create mapping: class_name ‚Üí final_class_id\nFINAL_CLASS_TO_ID = {cls: idx for idx, cls in enumerate(FINAL_CLASS_ORDER)}\n\nprint(\"\\nüìã Class Mapping Configuration:\")\nprint(f\"   Final class order: {FINAL_CLASS_ORDER}\")\nprint(f\"\\n   Roboflow class name mapping:\")\nfor old_name, new_name in ROBOFLOW_CLASS_NAME_MAPPING.items():\n    new_id = FINAL_CLASS_TO_ID[new_name]\n    print(f\"      {old_name} ‚Üí {new_name} (Final ID: {new_id})\")\nprint(f\"\\n   Roboflow label file ID mapping:\")\nfor old_id, class_name in ROBOFLOW_CLASS_ID_MAPPING.items():\n    final_name = ROBOFLOW_CLASS_NAME_MAPPING[class_name]\n    final_id = FINAL_CLASS_TO_ID[final_name]\n    print(f\"      ID {old_id} ({class_name}) ‚Üí {final_name} (Final ID: {final_id})\")\n\n# ============================================================================\n# DATASET PATHS\n# ============================================================================\nworking_dir = Path('/kaggle/working')\n\n# BSED dataset (already copied)\nbsed_dataset_dir = working_dir / 'yolo_classification_dataset'\n\n# Roboflow dataset (already copied)\nroboflow_dataset_dir = working_dir / 'Black-Sigatoka-4'\n\n# Combined dataset output\ncombined_dataset_dir = working_dir / 'combined_yolo_dataset'\n\nprint(f\"\\nüìÅ Dataset Paths:\")\nprint(f\"   BSED: {bsed_dataset_dir}\")\nprint(f\"   Roboflow: {roboflow_dataset_dir}\")\nprint(f\"   Combined Output: {combined_dataset_dir}\")\n\n# Validate datasets exist\nif not bsed_dataset_dir.exists():\n    raise FileNotFoundError(f\"BSED dataset not found: {bsed_dataset_dir}\")\nif not roboflow_dataset_dir.exists():\n    raise FileNotFoundError(f\"Roboflow dataset not found: {roboflow_dataset_dir}\")\n\n# Create combined dataset structure\nsplits = ['train', 'valid', 'test']\nfor split in splits:\n    (combined_dataset_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n    (combined_dataset_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n\nprint(f\"\\n‚úÖ Combined dataset directory structure created\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# FUNCTION: Update label file with new class mapping\n# ============================================================================\ndef update_label_file(label_path, old_to_new_class_mapping):\n    \"\"\"\n    Update YOLO label file with new class IDs.\n    \n    Args:\n        label_path: Path to .txt label file\n        old_to_new_class_mapping: Dict mapping old_class_id ‚Üí new_class_id\n    \n    Returns:\n        True if updated, False if no changes needed\n    \"\"\"\n    try:\n        with open(label_path, 'r') as f:\n            lines = f.readlines()\n        \n        updated_lines = []\n        changed = False\n        \n        for line in lines:\n            parts = line.strip().split()\n            if len(parts) >= 5:  # YOLO format: class_id x y w h\n                old_class_id = parts[0]\n                \n                # Check if this class needs mapping\n                if old_class_id in old_to_new_class_mapping:\n                    new_class_id = old_to_new_class_mapping[old_class_id]\n                    parts[0] = str(new_class_id)\n                    changed = True\n                \n                updated_lines.append(' '.join(parts) + '\\n')\n            else:\n                updated_lines.append(line)\n        \n        if changed:\n            with open(label_path, 'w') as f:\n                f.writelines(updated_lines)\n        \n        return changed\n    except Exception as e:\n        print(f\"Error updating {label_path}: {e}\")\n        return False\n\n# ============================================================================\n# FUNCTION: Rename image file with new class name\n# ============================================================================\ndef rename_image_with_class(filename, class_name_mapping):\n    \"\"\"\n    Rename image filename by replacing old class names with new ones.\n    \n    Args:\n        filename: Original filename (e.g., \"Functional-1-_png.rf.xxx.jpg\")\n        class_name_mapping: Dict mapping old_class_name ‚Üí new_class_name\n    \n    Returns:\n        New filename with updated class name\n    \"\"\"\n    new_filename = filename\n    \n    # Replace class names in filename (case-insensitive)\n    for old_name, new_name in class_name_mapping.items():\n        # Replace both capitalized and lowercase versions\n        if old_name in new_filename:\n            new_filename = new_filename.replace(old_name, new_name)\n        elif old_name.lower() in new_filename.lower():\n            # Case-insensitive replacement\n            pattern = re.compile(re.escape(old_name), re.IGNORECASE)\n            new_filename = pattern.sub(new_name, new_filename)\n    \n    return new_filename\n\n# ============================================================================\n# PROCESS ROBoFLOW DATASET: Map classes and copy files\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"üì¶ PROCESSING ROBoFLOW DATASET\")\nprint(\"=\"*80)\n\n# Load Roboflow data.yaml to understand structure\nroboflow_yaml_path = roboflow_dataset_dir / 'data.yaml'\nwith open(roboflow_yaml_path, 'r') as f:\n    roboflow_config = yaml.safe_load(f)\n\nroboflow_class_names = roboflow_config.get('names', [])\nprint(f\"\\nüìã Roboflow Original Classes from YAML: {roboflow_class_names}\")\n\n# Create mapping: old_class_id (from label files) ‚Üí new_class_id (final)\n# Label files use numeric IDs (0, 1, 2, 3), we need to map these to final IDs\nroboflow_class_id_mapping = {}\n\n# Handle different YAML formats\nif isinstance(roboflow_class_names, dict):\n    # Format: {0: 'Functional', 1: 'Mild', 2: 'Moderate', 3: 'Severe'}\n    for old_id, class_name in roboflow_class_names.items():\n        # Map class name to final class name\n        if class_name in ROBOFLOW_CLASS_NAME_MAPPING:\n            final_class_name = ROBOFLOW_CLASS_NAME_MAPPING[class_name]\n            final_id = FINAL_CLASS_TO_ID[final_class_name]\n            roboflow_class_id_mapping[str(old_id)] = str(final_id)\n        else:\n            # Fallback: try to use the ID mapping\n            if str(old_id) in ROBOFLOW_CLASS_ID_MAPPING:\n                mapped_name = ROBOFLOW_CLASS_ID_MAPPING[str(old_id)]\n                final_class_name = ROBOFLOW_CLASS_NAME_MAPPING[mapped_name]\n                final_id = FINAL_CLASS_TO_ID[final_class_name]\n                roboflow_class_id_mapping[str(old_id)] = str(final_id)\nelif isinstance(roboflow_class_names, list):\n    # Format: ['Functional', 'Mild', 'Moderate', 'Severe'] or ['0', '1', '2', '3']\n    for idx, class_name in enumerate(roboflow_class_names):\n        # Check if it's a class name or just an ID string\n        if isinstance(class_name, str) and class_name in ROBOFLOW_CLASS_NAME_MAPPING:\n            # It's a class name like 'Functional'\n            final_class_name = ROBOFLOW_CLASS_NAME_MAPPING[class_name]\n            final_id = FINAL_CLASS_TO_ID[final_class_name]\n            roboflow_class_id_mapping[str(idx)] = str(final_id)\n        elif str(idx) in ROBOFLOW_CLASS_ID_MAPPING:\n            # Use ID mapping (for cases where YAML has ['0', '1', '2', '3'])\n            mapped_name = ROBOFLOW_CLASS_ID_MAPPING[str(idx)]\n            final_class_name = ROBOFLOW_CLASS_NAME_MAPPING[mapped_name]\n            final_id = FINAL_CLASS_TO_ID[final_class_name]\n            roboflow_class_id_mapping[str(idx)] = str(final_id)\n\n# Also add direct ID mappings (in case YAML doesn't have names)\nfor old_id, class_name in ROBOFLOW_CLASS_ID_MAPPING.items():\n    if old_id not in roboflow_class_id_mapping:\n        final_class_name = ROBOFLOW_CLASS_NAME_MAPPING[class_name]\n        final_id = FINAL_CLASS_TO_ID[final_class_name]\n        roboflow_class_id_mapping[old_id] = str(final_id)\n\nprint(f\"\\nüîÑ Label File Class ID Mapping (for .txt files):\")\nfor old_id, new_id in sorted(roboflow_class_id_mapping.items(), key=lambda x: int(x[0])):\n    old_name = ROBOFLOW_CLASS_ID_MAPPING.get(old_id, 'Unknown')\n    final_name = ROBOFLOW_CLASS_NAME_MAPPING.get(old_name, 'Unknown')\n    print(f\"   Label ID {old_id} ({old_name}) ‚Üí Final ID {new_id} ({final_name})\")\n\n# Process each split\nroboflow_stats = {'train': 0, 'valid': 0, 'test': 0}\n\nfor split in splits:\n    print(f\"\\nüìÇ Processing Roboflow {split.upper()} split...\")\n    \n    # Source paths\n    src_images_dir = roboflow_dataset_dir / split / 'images'\n    src_labels_dir = roboflow_dataset_dir / split / 'labels'\n    \n    # Destination paths\n    dst_images_dir = combined_dataset_dir / split / 'images'\n    dst_labels_dir = combined_dataset_dir / split / 'labels'\n    \n    if not src_images_dir.exists() or not src_labels_dir.exists():\n        print(f\"   ‚ö†Ô∏è  Split {split} not found, skipping...\")\n        continue\n    \n    # Get all image files\n    image_files = list(src_images_dir.glob('*.jpg')) + list(src_images_dir.glob('*.png')) + \\\n                  list(src_images_dir.glob('*.JPG')) + list(src_images_dir.glob('*.PNG'))\n    \n    copied_count = 0\n    updated_count = 0\n    \n    for img_path in tqdm(image_files, desc=f\"  Copying {split} images\", leave=False):\n        # Rename image file: replace class names in filename\n        # Example: \"Functional-1-_png.rf.xxx.jpg\" ‚Üí \"Healthy-1-_png.rf.xxx.jpg\"\n        renamed_img_name = rename_image_with_class(img_path.name, ROBOFLOW_CLASS_NAME_MAPPING)\n        \n        # Use renamed filename directly (no prefix)\n        dst_img_name = renamed_img_name\n        dst_img_path = dst_images_dir / dst_img_name\n        \n        # Copy image with new name\n        shutil.copy2(img_path, dst_img_path)\n        \n        # Find and update corresponding label file\n        # Label file name should match the renamed image name\n        # Get the stem (filename without extension) from the renamed image\n        renamed_img_stem = Path(renamed_img_name).stem\n        label_name = img_path.stem + '.txt'  # Original label name\n        src_label_path = src_labels_dir / label_name\n        \n        # Label file should match the renamed image name\n        dst_label_name = renamed_img_stem + '.txt'  # Match the new image name exactly\n        dst_label_path = dst_labels_dir / dst_label_name\n        \n        if src_label_path.exists():\n            # Copy label file with new name\n            shutil.copy2(src_label_path, dst_label_path)\n            \n            # Update class IDs in label file\n            if update_label_file(dst_label_path, roboflow_class_id_mapping):\n                updated_count += 1\n            \n            copied_count += 1\n        else:\n            # If no label file, create one with default (whole image classification)\n            with open(dst_label_path, 'w') as f:\n                # YOLO format: class_id center_x center_y width height\n                # For whole image: 0.5 0.5 1.0 1.0\n                # Use first class as default (shouldn't happen, but safety)\n                default_class = list(roboflow_class_id_mapping.values())[0] if roboflow_class_id_mapping else '0'\n                f.write(f\"{default_class} 0.5 0.5 1.0 1.0\\n\")\n            copied_count += 1\n    \n    roboflow_stats[split] = copied_count\n    print(f\"   ‚úÖ Copied {copied_count} images, updated {updated_count} label files\")\n\nprint(f\"\\n‚úÖ Roboflow dataset processing complete!\")\nprint(f\"   Train: {roboflow_stats['train']} images\")\nprint(f\"   Valid: {roboflow_stats['valid']} images\")\nprint(f\"   Test: {roboflow_stats['test']} images\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# PROCESS BSED DATASET: Map classes and copy files\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"üì¶ PROCESSING BSED DATASET\")\nprint(\"=\"*80)\n\n# Load BSED data.yaml\nbsed_yaml_path = bsed_dataset_dir / 'data.yaml'\nwith open(bsed_yaml_path, 'r') as f:\n    bsed_config = yaml.safe_load(f)\n\nprint(f\"\\nüìã BSED Original Classes: {bsed_config.get('names', 'N/A')}\")\n\n# BSED classes: Stage1, Stage2, Stage3\n# These map directly to final classes (no remapping needed, just need to get correct IDs)\nbsed_class_id_mapping = {}\nbsed_class_names = bsed_config.get('names', {})\n\nif isinstance(bsed_class_names, dict):\n    # Format: {0: 'Stage1', 1: 'Stage2', 2: 'Stage3'}\n    for old_id, class_name in bsed_class_names.items():\n        new_id = FINAL_CLASS_TO_ID[class_name]\n        bsed_class_id_mapping[str(old_id)] = str(new_id)\nelif isinstance(bsed_class_names, list):\n    # Format: ['Stage1', 'Stage2', 'Stage3']\n    for old_id, class_name in enumerate(bsed_class_names):\n        new_id = FINAL_CLASS_TO_ID[class_name]\n        bsed_class_id_mapping[str(old_id)] = str(new_id)\n\nprint(f\"\\nüîÑ Class ID Mapping:\")\nfor old_id, new_id in bsed_class_id_mapping.items():\n    class_name = bsed_class_names[int(old_id)] if isinstance(bsed_class_names, dict) else bsed_class_names[int(old_id)]\n    print(f\"   BSED Class {old_id} ({class_name}) ‚Üí Final Class ID {new_id}\")\n\n# Process each split\nbsed_stats = {'train': 0, 'valid': 0, 'test': 0}\n\nfor split in splits:\n    print(f\"\\nüìÇ Processing BSED {split.upper()} split...\")\n    \n    # Source paths\n    src_images_dir = bsed_dataset_dir / split / 'images'\n    src_labels_dir = bsed_dataset_dir / split / 'labels'\n    \n    # Destination paths\n    dst_images_dir = combined_dataset_dir / split / 'images'\n    dst_labels_dir = combined_dataset_dir / split / 'labels'\n    \n    if not src_images_dir.exists() or not src_labels_dir.exists():\n        print(f\"   ‚ö†Ô∏è  Split {split} not found, skipping...\")\n        continue\n    \n    # Get all image files\n    image_files = list(src_images_dir.glob('*.jpg')) + list(src_images_dir.glob('*.png')) + \\\n                  list(src_images_dir.glob('*.JPG')) + list(src_images_dir.glob('*.PNG'))\n    \n    copied_count = 0\n    updated_count = 0\n    \n    for img_path in tqdm(image_files, desc=f\"  Copying {split} images\", leave=False):\n        # Copy image (use original name, no prefix)\n        dst_img_name = img_path.name\n        dst_img_path = dst_images_dir / dst_img_name\n        shutil.copy2(img_path, dst_img_path)\n        \n        # Find and update corresponding label file\n        label_name = img_path.stem + '.txt'\n        src_label_path = src_labels_dir / label_name\n        dst_label_name = label_name  # Use original name, no prefix\n        dst_label_path = dst_labels_dir / dst_label_name\n        \n        if src_label_path.exists():\n            # Copy label file\n            shutil.copy2(src_label_path, dst_label_path)\n            \n            # Update class IDs in label file\n            if update_label_file(dst_label_path, bsed_class_id_mapping):\n                updated_count += 1\n            \n            copied_count += 1\n        else:\n            # If no label file, create one\n            with open(dst_label_path, 'w') as f:\n                default_class = list(bsed_class_id_mapping.values())[0] if bsed_class_id_mapping else '0'\n                f.write(f\"{default_class} 0.5 0.5 1.0 1.0\\n\")\n    \n    bsed_stats[split] = copied_count\n    print(f\"   ‚úÖ Copied {copied_count} images, updated {updated_count} label files\")\n\nprint(f\"\\n‚úÖ BSED dataset processing complete!\")\nprint(f\"   Train: {bsed_stats['train']} images\")\nprint(f\"   Valid: {bsed_stats['valid']} images\")\nprint(f\"   Test: {bsed_stats['test']} images\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CREATE COMBINED DATA.YAML\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"üìù CREATING COMBINED DATA.YAML\")\nprint(\"=\"*80)\n\n# Create final class mapping for YAML\nfinal_class_names = {idx: name for idx, name in enumerate(FINAL_CLASS_ORDER)}\n\n# Create combined data.yaml\ncombined_yaml_config = {\n    'path': str(combined_dataset_dir.absolute()),\n    'train': 'train/images',\n    'val': 'valid/images',\n    'test': 'test/images',\n    'names': final_class_names,\n    'nc': len(FINAL_CLASS_ORDER)\n}\n\n# Save combined data.yaml\ncombined_yaml_path = combined_dataset_dir / 'data.yaml'\nwith open(combined_yaml_path, 'w') as f:\n    yaml.dump(combined_yaml_config, f, default_flow_style=False, sort_keys=False)\n\nprint(f\"\\n‚úÖ Combined data.yaml created: {combined_yaml_path}\")\nprint(f\"\\nüìã Configuration:\")\nprint(f\"   Path: {combined_yaml_config['path']}\")\nprint(f\"   Train: {combined_yaml_config['train']}\")\nprint(f\"   Validation: {combined_yaml_config['val']}\")\nprint(f\"   Test: {combined_yaml_config['test']}\")\nprint(f\"   Number of classes: {combined_yaml_config['nc']}\")\nprint(f\"\\n   Class mapping:\")\nfor idx, name in final_class_names.items():\n    print(f\"      {idx}: {name}\")\n\n# ============================================================================\n# FINAL STATISTICS\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"üìä FINAL COMBINED DATASET STATISTICS\")\nprint(\"=\"*80)\n\ntotal_stats = {\n    'train': bsed_stats['train'] + roboflow_stats['train'],\n    'valid': bsed_stats['valid'] + roboflow_stats['valid'],\n    'test': bsed_stats['test'] + roboflow_stats['test']\n}\n\nprint(f\"\\nüìà Total Images:\")\nprint(f\"   Training: {total_stats['train']} images\")\nprint(f\"   Validation: {total_stats['valid']} images\")\nprint(f\"   Test: {total_stats['test']} images\")\nprint(f\"   TOTAL: {sum(total_stats.values())} images\")\n\nprint(f\"\\nüì¶ Source Breakdown:\")\nprint(f\"   BSED Dataset:\")\nprint(f\"      Train: {bsed_stats['train']}, Valid: {bsed_stats['valid']}, Test: {bsed_stats['test']}\")\nprint(f\"   Roboflow Dataset:\")\nprint(f\"      Train: {roboflow_stats['train']}, Valid: {roboflow_stats['valid']}, Test: {roboflow_stats['test']}\")\n\n# Verify label files match\nprint(f\"\\nüîç Verifying label files...\")\nfor split in splits:\n    images_dir = combined_dataset_dir / split / 'images'\n    labels_dir = combined_dataset_dir / split / 'labels'\n    \n    if images_dir.exists() and labels_dir.exists():\n        images = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png')) + \\\n                 list(images_dir.glob('*.JPG')) + list(images_dir.glob('*.PNG'))\n        labels = list(labels_dir.glob('*.txt'))\n        \n        print(f\"   {split.upper()}: {len(images)} images, {len(labels)} labels\", end=\"\")\n        if len(images) == len(labels):\n            print(\" ‚úÖ\")\n        else:\n            print(f\" ‚ö†Ô∏è  (mismatch!)\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ DATASET COMBINATION COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"\\nüìÅ Combined dataset location: {combined_dataset_dir}\")\nprint(f\"üìÑ Configuration file: {combined_yaml_path}\")\n\n# ============================================================================\n# CLEANUP: Delete copied datasets to save space\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"üßπ CLEANING UP COPIED DATASETS\")\nprint(\"=\"*80)\n\n# Option to skip cleanup (set to False if you want to keep the copies)\nDELETE_COPIED_DATASETS = True\n\nif DELETE_COPIED_DATASETS:\n    print(\"\\nüóëÔ∏è  Deleting copied datasets (already merged)...\")\n    \n    # Delete BSED copied dataset\n    if bsed_dataset_dir.exists():\n        try:\n            shutil.rmtree(bsed_dataset_dir)\n            print(f\"   ‚úÖ Deleted: {bsed_dataset_dir}\")\n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è  Error deleting {bsed_dataset_dir}: {e}\")\n    else:\n        print(f\"   ‚ÑπÔ∏è  BSED dataset not found (already deleted or not copied)\")\n    \n    # Delete Roboflow copied dataset\n    if roboflow_dataset_dir.exists():\n        try:\n            shutil.rmtree(roboflow_dataset_dir)\n            print(f\"   ‚úÖ Deleted: {roboflow_dataset_dir}\")\n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è  Error deleting {roboflow_dataset_dir}: {e}\")\n    else:\n        print(f\"   ‚ÑπÔ∏è  Roboflow dataset not found (already deleted or not copied)\")\n    \n    print(f\"\\n‚úÖ Cleanup complete! Only combined dataset remains.\")\n    print(f\"   Combined dataset: {combined_dataset_dir}\")\nelse:\n    print(\"\\nüí° Cleanup skipped (DELETE_COPIED_DATASETS = False)\")\n    print(f\"   BSED dataset: {bsed_dataset_dir}\")\n    print(f\"   Roboflow dataset: {roboflow_dataset_dir}\")\n    print(f\"   Combined dataset: {combined_dataset_dir}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"üí° Next step: Use this dataset for training:\")\nprint(f\"   from ultralytics import YOLO\")\nprint(f\"   model = YOLO('yolov8n.pt')\")\nprint(f\"   model.train(data='{combined_yaml_path}', epochs=100)\")\nprint(\"=\"*80)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/BananaEarlyDataSets.zip /kaggle/working","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}